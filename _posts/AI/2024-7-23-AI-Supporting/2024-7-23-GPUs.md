---
layout: post
title: 【AI Supporting】01 GPUs
categories: [AI, Supporting]
tags: [GPU]
---

## 1 params for GPUs


|English terminolgy | Chinese description |
|---|---|
| GPU Chip（GPU芯片）| - GPU芯片是图形处理器（GPU）的核心部件，负责图形渲染和计算。<br/> - GPU芯片由多个处理器单元（处理器单元）组成，每个处理器单元负责处理特定类型的计算任务，如顶点着色、像素着色、几何着色等。|
| Memory（显存）| - 视频存储器(Video memory,)，也称为视频随机存取存储器（VRAM），是计算机显卡或图形处理单元 (GPU) 上的专用内存，用于存储和管理与图形和视频处理相关的数据。<br/> - GPU 内存的作用是临时存储图形、图像、视频、缓冲区加载和纹理。在进行游戏、编辑和设计等图形处理时，它会根据需要将视频数据临时保存在 GPU 内存中，以便不时执行所需的处理。|
| Memory Bandwidth| - 显存带宽（Video memory bandwidth），是指显卡的GPU与显存之间的数据传输速率。<br/> - 显存带宽越高，表示显卡处理图形和视频数据的效率越高。|
| GPU Clock（GPU时钟）| - GPU时钟是指显卡中图形处理器（GPU）的工作时钟频率。 <br/> - 它决定了GPU在单位时间内执行图形计算和渲染任务的速度。较高的GPU时钟频率通常表示更快的图形处理性能。|
| Memory Clock（内存时钟）| - 内存时钟是指显卡上的显存（VRAM）的工作时钟频率。 <br/> - 它决定了显存读取和写入数据的速度。较高的内存时钟频率可以提供更快的数据传输速度，对于高分辨率的游戏和图形应用程序尤其重要。|
| Shader Clock（着色器时钟）| - 着色器时钟是指显卡上的着色器单元（负责图形效果和计算任务）的工作频率。 <br/> - 它决定了着色器单元在单位时间内执行着色器代码的速度。较高的着色器时钟频率可以提供更快的图形效果和计算性能。|
| Base Clock（基础时钟）|基础时钟是显卡的默认工作频率，类似于显卡的“基础速度”。它决定了显卡整体的基本性能水平。|
| Boost Clock（增强时钟）| - 增强时钟是显卡在负载较重时能够自动提升的最高频率。 <br/> - 它允许显卡在需要更高性能时临时提升工作频率，以应对更复杂的计算和渲染任务。Boost Clock通常在短时间内提供更高的性能。|
| GPU Tweak（显卡超频）|- 在显卡超频中，你可以增加显卡的GPU时钟频率和内存时钟频率，以提高显卡的性能。 <br/> - 增加GPU时钟频率可以加快图形处理器的计算速度，从而提高图形渲染和游戏性能。 <br/> - 增加内存时钟频率可以提升显存读写速度，从而加快数据传输和加载速度。|
|Shaders（着色器）| - Shaders是GPU中负责执行图形渲染中各种程序的处理器单元。它们处理顶点着色、像素着色、几何着色等任务，负责计算3D场景中物体的光照、颜色、纹理和阴影等视觉效果。<br/> - Shaders的数量直接影响到GPU处理复杂图形和特效的能力。例如，如果一款GPU的Shaders数量为1280，意味着它拥有1280个并行处理单元来执行着色计算|
|TMUs | - （Texture Mapping Units，纹理映射单元）<br/> - TMUs负责处理纹理贴图，即将2D纹理图像映射到3D模型表面的过程。它们从内存中读取纹理数据，并将其应用到场景中的几何体上，增加场景的真实感和细节。<br/> - TMUs的数量决定了GPU同时处理纹理的能力。例如，如果一个GPU配置为56个TMUs，这表示它可以并行处理56个纹理采样操作。|
|ROPs | - （Raster Operations Pipelines，光栅化操作管道）<br/> - ROPs负责最后阶段的像素处理，包括像素的混合、抗锯齿、透明度处理以及输出到帧缓冲区等。<br/> - ROPs数量决定了GPU每时钟周期可以完成的像素处理数量，影响着输出图像的质量和最终渲染的速度。例如，如果GPU具有32个ROPs，说明它能并行处理32个像素的光栅化操作。|


|	 Product Name 	|	Theoretical Performance <br/> /  FP32 (float)	|	 Memory Size / Type / Bus / Bandwidth 	|	 Shaders / TMUs / ROPs 	|
|	 ------------------------- 	|	 -------------- 	|	 ---------------------- 	|	 --------------------- 	|
|	 A100 PCIe 40 GB 	|	19.49 TFLOPS	|	 40 GB, HBM2e, 5120 bit, 1.56 TB/s 	|	 6912 / 432 / 160 	|
|	 A100 PCIe 80 GB 	|		|	 80 GB, HBM2e, 5120 bit 	|	 6912 / 432 / 160 	|
|	 A100 SXM4 40 GB 	|		|	 40 GB, HBM2e, 5120 bit 	|	 6912 / 432 / 160 	|
|	 A100 SXM4 80 GB 	|		|	 80 GB, HBM2e, 5120 bit 	|	 6912 / 432 / 160 	|
|	 A100X 	|		|	 80 GB, HBM2e, 5120 bit 	|	 6912 / 432 / 160 	|
|	 A800 PCIe 40 GB 	|	19.49 TFLOPS	|	 40 GB, HBM2e, 5120 bit, 1.56 TB/s 	|	 6912 / 432 / 160 	|
|	 A800 PCIe 80 GB 	|		|	 80 GB, HBM2e, 5120 bit 	|	 6912 / 432 / 160 	|
|	 A800 SXM4 80 GB 	|		|	 80 GB, HBM2e, 5120 bit 	|	 6912 / 432 / 160 	|
|	 GeForce RTX 2080 Ti 	|	13.45 TFLOPS	|	 11 GB, GDDR6, 352 bit, 616.0 GB/s 	|	 4352 / 272 / 88 	|
|	 GeForce RTX 2080 Ti 12 GB 	|		|	 12 GB, GDDR6, 384 bit 	|	 4608 / 288 / 96 	|
|	 GeForce RTX 3090 	|	35.58 TFLOPS	|	 24 GB, GDDR6X, 384 bit, 936.2 GB/s 	|	 10496 / 328 / 112 	|
|	 GeForce RTX 3090 Ti 	|		|	 24 GB, GDDR6X, 384 bit 	|	 10752 / 336 / 112 	|
|	 GeForce RTX 4090 	|	82.58 TFLOPS	|	 24 GB, GDDR6X, 384 bit, 1.01 TB/s 	|	 16384 / 512 / 176 	|
|	 GeForce RTX 4090 D 	|		|	 24 GB, GDDR6X, 384 bit 	|	 14592 / 456 / 176 	|
|	 GeForce RTX 4090 Max-Q 	|		|	 16 GB, GDDR6, 256 bit 	|	 9728 / 304 / 112 	|
|	 GeForce RTX 4090 Mobile 	|		|	 16 GB, GDDR6, 256 bit 	|	 9728 / 304 / 112 	|
|	 GeForce RTX 4090 Ti 	|		|	 24 GB, GDDR6X, 384 bit 	|	 18176 / 568 / 192 	|
|	 TITAN RTX 	|	11.76 TFLOPS	|	 24 GB, GDDR6, 384 bit, 672.0 GB/s 	|	 4608 / 288 / 96 	|
|	 Tesla P40 	|	11.76 TFLOPS	|	 24 GB, GDDR5, 384 bit, 347.1 GB/s 	|	 3840 / 240 / 96 	|
|	Tesla T4 	|	8.141 TFLOPS	|	 16 GB, GDDR6, 256 bit, 320.0 GB/s 	|	 2560 / 160 / 64 	|
|	Tesla T4G 	|		|	 16 GB, GDDR6, 256 bit 	|	 2560 / 160 / 64	|
|	 Tesla V100 DGXS 16 GB 	|	16.20 TFLOPS	|	 16 GB, HBM2, 4096 bit, 897.0 GB/s 	|	 5120 / 320 / 128 	|
|	 Tesla V100 DGXS 32 GB 	|		|	 32 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 FHHL 	|		|	 16 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 PCIe 16 GB 	|		|	 16 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 PCIe 32 GB 	|		|	 32 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 SXM2 16 GB 	|		|	 16 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 SXM2 16 GB 	|		|	 16 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 SXM2 32 GB 	|		|	 32 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100 SXM3 32 GB 	|		|	 32 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|
|	 Tesla V100S PCIe 32 GB 	|		|	 32 GB, HBM2, 4096 bit 	|	 5120 / 320 / 128 	|

> doc:
> - [multi clock](https://juejin.cn/post/7242145395723337785)
> - [Shaders / TMUs / ROPs](https://blog.csdn.net/flomingo1/article/details/138303145)
> - [gpu database](https://www.techpowerup.com/gpu-specs/)
> - [why Ti?](https://www.quora.com/What-does-Ti-mean-in-a-GPU-name-Is-it-better-than-the-original-one-with-no-Ti-at-all)

## 2 difference between training card and inference card

首先要了解神经网络训练和推理时的差别，然后自然就知道对GPU的需求的差别。

先看一下训练时的需求。神经网络训练通常使用随机梯度下降算法，显存中除了加载模型参数，还需要保存中间状态，主要是梯度信息，相比推理，显存需求要增加几倍，显存要够大才能跑起来；要训练好的模型，需要使用大量数据，大量数据要读入显存，显存带宽要够大；另外对于当前的大数据量，单卡已经无法满足要求，要用多卡集群训练，集群训练要在多机间通信，要交换大量数据，要支持更高的通信带宽，接口一般用NVLINK，通常还要GPU支持RDMA特性，能够直接在显存和通信卡内存间搬数据。

总结起来就是：
- 训练卡要求显存大，显存带宽大，和外部通信接口带宽大，算力就不说了，都不是主要考虑问题了，训练卡目前主要是NVIDIA的A100 V100。
- 推理时的需求就简单了，算力和显存平衡就可了，模型能装的进去，把算力跑慢就可以了，显存和算力越大，推理的并发数越多，T4跑推理挺好，便宜，算力也够强。

> 算力：
> - 算力最基本的计量单位是 FLOPS，英文 Floating-point Operations Per Second，即每秒执行的浮点运算次数。浮点运算其实就是带小数的加减乘除运算。

doc:
- 训练卡vs推理卡: https://developer.aliyun.com/article/1259910
- 算力: https://www.cnblogs.com/upyun/p/17969963
- cpu理论浮点运算值: https://blog.csdn.net/qq_42309265/article/details/123098538

